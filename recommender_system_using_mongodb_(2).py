# -*- coding: utf-8 -*-
"""Recommender_system_using_Mongodb (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eYmWJMClkFe656u1h2ZP3CAXhuAj6FwB

# #RESTAURANT RECOMMENDER SYSTEM


This data set consists of restaurants of Hyderabad/India collected from Zomato.

Expected Outcome:

*   We will write a restaurant name,
*   Recommender system will look at the reviews of other restaurants
*   System will recommend us other restaurants with similar reviews and  sort them from the highest rated.

##Connecting Mongodb to python
"""

!pip install pymongo[srv]

import pymongo
from pymongo import MongoClient

client = MongoClient("mongodb+srv://Kulveen-24:Kulveen1524@cluster0.y56g1.mongodb.net/myFirstDatabase?retryWrites=true&w=majority")

db = client["test"]
collection= db["test"]

db

collection

"""##Retreiving Results from Mongodb"""

results = collection.find()
for x in results:
    print(type(x))

results = collection.find()
for x in results:
    print(x)

import pandas as pd
data1 = pd.DataFrame(list(collection.find()))

collection2= db["test1"]

results = collection2.find()
for x in results:
    print(x)

"""##Converting Dictionary into pandas Dataframe"""

data2 = pd.DataFrame(list(collection2.find()))

data1.head()

data2.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')

data1.info()

data1.nunique()

data1.info()

data2.nunique()

data2 = data2.rename(columns={'Restaurant': 'Name'})

df = pd.merge(data2, data1, how='left', on='Name')

df.drop(['Reviewer', 'Time', 'Pictures', 'Links', 'Collections'], axis=1, inplace=True)
df.head()

df.drop('_id_x',
  axis='columns', inplace=True)
df.drop('_id_y',
  axis='columns', inplace=True)

df['Cost'] = df['Cost'].str.replace(',', '').astype(int)
df['Rating'] = df['Rating'].str.replace('Like', '1').astype(float)
df.info()

print('Nu of data inputs:', len(df))
print('\nNu of NaN values for each column:\n')
print(df.isnull().sum())

df['Name'][df['Rating'].isnull() == True].value_counts()

print('Mean of Rating for American Wild Wings: ', df['Rating'][df['Name'] == 'American Wild Wings'].mean())
print('Mean of Rating for Arena Eleven: ', df['Rating'][df['Name'] == 'Arena Eleven'].mean())
print('Overall Mean of Ratings: ', df['Rating'].mean())

df['Rating'].fillna(4, inplace=True)

df['Review'] = df['Review'].fillna('-')
df.isnull().sum()

"""##Separating Metadata (Reviews and Followers)"""

df['Metadata'].fillna('0 Review , 0 Follower', inplace=True)

df['Metadata'] = df['Metadata'].str.replace('Reviews', 'Review')
df['Metadata'] = df['Metadata'].str.replace('Followers', 'Follower')

df['Metadata'][df['Metadata'].str.endswith('w')] = df['Metadata'][df['Metadata'].str.endswith('w')] + ' , - Follower'

df[['Reviews', 'Followers']] = df['Metadata'].str.split(' , ', expand=True)

df['Reviews'] = df['Reviews'].str.replace('Review', '')
df['Reviews'] = df['Reviews'].str.replace('Posts', '')
df['Reviews'] = df['Reviews'].str.replace('Post', '')

df['Followers'] = df['Followers'].str.replace('Follower', '')
df['Followers'] = df['Followers'].str.replace('-', '0')

df[['Reviews', 'Followers']] = df[['Reviews', 'Followers']].astype(int)

df.drop(['Metadata'], axis=1, inplace=True)

df = df.sort_values(['Name', 'Cost'], ascending=False).reset_index()
df.drop('index', axis=1, inplace=True)

df.head()



"""##Creating New Features (Mean of Ratings, Reviews, and Followers)"""

restaurants = list(df['Name'].unique())
df['Mean Rating'] = 0
df['Mean Reviews'] = 0
df['Mean Followers'] = 0

for i in range(len(restaurants)):
    df['Mean Rating'][df['Name'] == restaurants[i]] = df['Rating'][df['Name'] == restaurants[i]].mean()
    df['Mean Reviews'][df['Name'] == restaurants[i]] = df['Reviews'][df['Name'] == restaurants[i]].mean()
    df['Mean Followers'][df['Name'] == restaurants[i]] = df['Followers'][df['Name'] == restaurants[i]].mean()

df.sample(3)

"""##Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range = (1,5))

df[['Mean Rating', 'Mean Reviews', 'Mean Followers']] = scaler.fit_transform(df[['Mean Rating', 'Mean Reviews', 'Mean Followers']]).round(2)

df.sample(3)

"""##Text Preprocessig and Cleaning"""

import re
import nltk
nltk.download("stopwords")
from sklearn.feature_extraction.text import CountVectorizer

df[['Review', 'Cuisines']].sample(5)

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

replace_space = re.compile('[/(){}\[\]\|@,;]')

remove_symbols = re.compile('[^0-9a-z #+_]')

stop_words = set(stopwords.words('english'))

def text_preprocessing(text):
    text = text.lower()

    text = replace_space.sub(' ', text)

    text = remove_symbols.sub('', text)

    text = ' '.join(word for word in text.split() if word not in stop_words)

    return text

df['Review'] = df['Review'].apply(text_preprocessing)
df['Cuisines'] = df['Cuisines'].apply(text_preprocessing)

df[['Review','Cuisines']].sample(5)

"""##EDA - Analysing Restaurants and Popularities"""

# RESTAURANT NAMES:
restaurant_names = list(df['Name'].unique())
restaurant_names

df_rating = df.drop_duplicates(subset='Name')
df_rating = df_rating.sort_values(by='Mean Rating', ascending=False).head(10)

plt.figure(figsize=(7,5))
sns.barplot(data=df_rating, x='Mean Rating', y='Name', palette='RdBu')
plt.title('Top Rated 10 Restaurants');

df_reviews = df.drop_duplicates(subset='Name')
df_reviews = df_reviews.sort_values(by='Mean Reviews', ascending=False).head(10)

plt.figure(figsize=(7,5))
sns.barplot(data=df_reviews, x='Mean Reviews', y='Name', palette='RdBu')
plt.title('Top Reviewed 10 Restaurants');

df_followers = df.drop_duplicates(subset='Name')
df_followers = df_followers.sort_values(by='Mean Followers', ascending=False).head(10)

plt.figure(figsize=(7,5))
sns.barplot(data=df_followers, x='Mean Followers', y='Name', palette='RdBu')
plt.title('Most Followed Top 10 Restaurants');

"""##EDA - Word Frequency Distribution:"""

def get_top_words(column, top_nu_of_words, nu_of_word):

    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')

    bag_of_words = vec.fit_transform(column)

    sum_words = bag_of_words.sum(axis=0)

    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]

    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)

    return words_freq[:top_nu_of_words]

# Top 20 two word frequencies for Cuisines
list1 = get_top_words(df['Cuisines'], 20, (2,2))

df_words1 = pd.DataFrame(list1, columns=['Word', 'Count'])

plt.figure(figsize=(7,6))
sns.barplot(data=df_words1, x='Count', y='Word')
plt.title('Word Couple Frequency for Cuisines');

# Top 20 two word frequencies for Reviews
list2 = get_top_words(df['Review'], 20, (2,2))

df_words2 = pd.DataFrame(list2, columns=['Word', 'Count'])

plt.figure(figsize=(7,6))
sns.barplot(data=df_words2, x='Count', y='Word')
plt.title('Word Couple Frequency for Reviews');

"""##CONTENT BASE RECOMMENDER SYSTEM

###TF-IDF Matrix (Term Frequency â€” Inverse Document Frequency Matrix)
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel
df.set_index('Name', inplace=True)

indices = pd.Series(df.index)

tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['Review'])

cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)

"""###Creating the Recommender System:"""

def recommend(name, cosine_similarities = cosine_similarities):

    recommend_restaurant = []

    idx = indices[indices == name].index[0]

    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)

    top30_indexes = list(score_series.iloc[0:31].index)

    for each in top30_indexes:
        recommend_restaurant.append(list(df.index)[each])

    df_new = pd.DataFrame(columns=['Cuisines', 'Mean Rating', 'Cost', 'Timings'])

    for each in recommend_restaurant:
        df_new = df_new.append(pd.DataFrame(df[['Cuisines','Mean Rating', 'Cost', 'Timings']][df.index == each].sample()))

    df_new = df_new.drop_duplicates(subset=['Cuisines','Mean Rating', 'Cost'], keep=False)
    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)

    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))

    return df_new

"""##Testing the Recommender System
### Example 1:
"""

df[df.index == 'Hyderabadi Daawat'].head(1)

# WHAT ARE WE GOING TO BE RECOMMENDED:
recommend('Hyderabadi Daawat')

"""

###Example 2:"""

# BAKERY.
df[df.index == 'Labonel'].head(1)

# WHAT ARE WE GOING TO BE RECOMMENDED:
recommend('Labonel')

"""###Example 3:"""

# BBQ RESTAURANT
df[df.index == 'Barbeque Nation'].sample(1)

#WHAT ARE WE GOING TO BE RECOMMENDED:
recommend('Barbeque Nation')